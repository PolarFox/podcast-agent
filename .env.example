# Backend selection
PROCESSING_BACKEND=ollama  # or gemini

# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b-instruct

# Gemini
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_MODEL=gemini-1.5-flash

# GitHub
GITHUB_TOKEN=ghp_your_pat_here
GITHUB_REPOSITORY=owner/repo

# Logging
LOG_LEVEL=INFO
